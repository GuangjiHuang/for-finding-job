* DCGAN的原理
GAN就是生成对抗性网络的意思。这是一个网络，DC表示的是由直接的卷积层组成的网络。这个模型的组成的话，有两部分，一个是生成器，另一个是判别器。然后说一下它们的工作原理，生成器的输入就是一个随机数，输出一张我们希望得到的图像，这个图像我们希望它和我们的目标很像。然后判别器本质上就是一个分类器，我们把原来真实的数据的标签标为1，我们通过生成器生成的样本数据的标签标为0。假设我们已经提前训练了分类器，把我们的真实样本和生成的样本打好标签之后，给到分类器去进行分类，如果分类器的识别率很高，就是说分类器很容易识别出生成器生成的是假的样本，我们就人为生成器的性能不足，并且以分类器的结果作为生成器的loss，继续训练生成器，直到生成器生成的图像数据被判别器无法识别为是真样本还是假样本的地步为止。

* 这个比赛为什么会想到使用DCGAN？
因为GAN是典型的数据增强的方法。我们可以通过它来生成一些新的数据。这些数据具有原来的object有具有的特征，但是又和原来的图像不一样，这种不一样是和那种对原图通过形变，颜色变换，加噪声或者滤波之后的图像不一样。传统的方法都是基于原图进行修改，得到的其实是和原图差不多特征的数据。而GAN生成的是完全新的数据，并且这个数据和要表征的object很逼真，丰富了特征的多样性。这是一种更加高级的数据增强的方法。
最基本的GAN网络，它的网络内部是使用全连接层搭建的。DCGAN使用的是卷积层搭建的。实验证明DCGAN的效果比GAN的效果要好。为什么？
-》GAN可以用来拟合原始的数据分布，什么叫做拟合数据分布，就是给你一个训练数据，你能通过GAN这个工具，产生和这个数据分布相似的一些数据。







* 相关的问题：
  （1）pytorch中的反卷积的api函数的参数是怎样的，和卷积的函数有什么区别？

  （2）进行反卷积时候的上采样忘记了公式是怎样的？

  （3）conv2d以及ConvTranspose2d中，它的参数的顺序是in_channels, out_channels, kernel_size, 然后是strip以及padding，到底哪个先呢？为什么？

  -》 我觉得应该是strip先的，因为要进行上采样或者下采样，都是stride=2， 所以，然后再根据这个stride去计算padding的。
  （4）权重的初始化的方式有哪些？【今晚一定要仔细看看，然后自己测试一下，敲代码测试一下。30mins】

  （5）怎样指定不规则的kernel以及不规则的padding。在pytorch中，使用tupple（3， 5）。

  （6）leaky relu中的x小于0的那段的斜率一般怎样选？你的模型是选择的是多少？为什么这样选？
  -》我看到DCGAN这里是选择0.2的。

  （7）view和reshape的差异的比较。因为我看到一般都是使用view的，很少是使用reshape的。

  （8）
