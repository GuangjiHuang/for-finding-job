# ==0. 自我介绍==

（1）面试官您好，首先就是非常感觉您能够抽出宝贵的时间来面试我。我叫黄光积。本科和硕士都是就读于华南理工大学的自动化学院。现在是刚上研三，明年毕业。我的研究方向是是关于人工智能这一块的，研究的课题是智能扶梯监控。

（2）我的简历上写了一个项目和比赛。然后呢这个项目也是我课题做的方向，这是一个广州市科技局的项目，是我们实验室和日立电梯那边合作一起合作的。它的任务是要开发一个手扶电梯智能监控系统，实现扶梯场景下的客流统计以及扶手带上的异物探出的检测。我负责的是这个智能系统的算法实现。在客流统计这个任务上，我们做到的算法的准确率达到96%。在扶手带异物检测这个任务上，我们做到的异物检测准确率达到95%。然后使用Tensort框架将模型部署到英伟达的Jetson Xavier嵌入式平台上，达到27FPS的实时检测效果。

（3）研究生期间我还和实验室的同学组队参加了阿里天池的一个比赛。这个比赛是以数据为中心的鲁棒机器学习。它的任务就是给定一定的图片的数据，让我们训练出一个效果比较好的鲁棒的模型。然后就是我们取得的成绩是：初赛成绩是在3000多支队伍中排名40多名，复赛成绩是在50支队伍中排名37名。我的自我介绍完毕，请多多指教，谢谢！


# ==一. 检测==
### 0. 介绍一下这个项目
==（1）项目的背景：==
	这个项目是和一日立电梯那边合作的一个项目，它的应用场景是扶梯场景下的监控。这个项目要做什么呢？首先就是实现扶梯场景下的客流量的检测，还有一个就是安全检测，检测扶梯上的扶手带上有没有异物的伸出，扶梯在运行过程中，如果有人把手后者头或者其它的物体伸出了扶手带区域，可能会发生危险，这个是必要进行检测的。最后需要将我们的算法和模型部署到英伟达的开发板上进行实际的落地。
==（2）采用的关键的技术和方法==
	对于客流检测的话，我们用的方法是使用速度比较快的yolov4进行检测，然后就是使用卡尔曼滤波和KM匹配算法实现目标的跟踪，通过乘客的运动的轨迹实现人流量的统计。
	对于扶手带上的异物的检测的话，我们应该的是前景提取的方法，将扶手带作为背景建模，建立一个高斯混合模型，高斯混合模型判断后续的视频帧的扶手带上的每一个像素进行分类，判断它是属于背景还是属于前景。然后使用==什么方法==对像素进行连通合并，得到一个连通的前景区域。那么我们是怎样判断这个前景区域是不是异物呢？我们通过面积进行判断。
	最后是将模型部署到英伟达的Jetson axvier中，使用tensorrt框架实现加速，同时进行一个int8量化，达到模型加速的效果。
==（3）难点以及解决办法==
	1）客流拥堵的时候，存在遮挡的问题。遮挡会导致模型漏检，漏检导致跟跟踪器的人头跟踪丢失。在这个问题上，我们从三个方面进行考虑，首先是数据集，我们模拟生成了很多实际场景遮挡的数据集用来训练模型。同时在模型的后处理方面，我们使用了自适应NMS的IoU阈值的方法以及自适应自信度的方法。在跟踪算法上也进行了一个优化，使用DIoU替代IoU，然后进行了一个二次匹配来缓解遮挡问题。
	~~2）扶手带异物检测的时候，距离摄像头一端会比较的大，远离摄像头的一端的扶手带会显得很窄。这就是一个问题了。~~
	3）需要部署到端侧的嵌入式平台上，需要达到实时检测的效果。所以需要进行加速和量化等优化。我们使用了tensorrt的框架，并且进行了int8的量化来进行加速。

==（4）最后的结果==

​	1）在客流统计上，准确率达到95%。扶手带异物检测上，准确率达到96%。最后部署到英伟达的Jetson xvier上，达到了27帧每秒的实时检测效果。

### 1. 模型修改部分

#### （1）介绍一下copy paste

​	==背景和目的==：使用这个方法是为了解决数据的跨域训练和测试的问题，深度学习一般会出现这样的一个情况，就是使用数据集训练好了一个模型，然后在应用这个模型进行推理测试的时候，在某些场景下，效果可能会很好，但是在另外一下场景下的效果不好。并且我们这个训练集的人头数据并不是都来源于扶梯的场景，而是大多的数据都是来源于其它的场景，因为这是一个公共的数据集，比如说是教室，会议室等场景。因为需要保密的问题，实际上的扶梯的数据集是不能泄漏的，所以找不到真正扶梯应用场景下大量数据集。然后就是，我们向企业那边拿了一些数据集，数据集也是非常的有限，这个数据集我们都用作了测试集。
​	copy paste翻译过来就是复制粘贴，就是从别的场景下标注的数据复制过来，然后粘贴到我们实际使用的应用场景，比如现在我们项目的这个扶梯下的场景。

​	引入copy paste就是解决这样的一个问题，就是训练集上的数据的场景和实际应用的场景的不同的问题。其实，现实中，这种问题应该会比较的常见。效果的话，应用了copy paste，大概可以可高3个百分点。


​	这是一个数据增强的方法，在模型训练之前进行处理的。

copy paste还可以解决一个正样本和负样本极度不均衡的问题，比如说一般的图像，整张图可能就是几个目标人头，也就是说正样本的数量是非常的少的。但是我们在进行copy paste之后，一个图像的目标数会比较的多，roi区域的目标数相对会比较的稠密。增加了正样本的数量。



#### （2）改变了模型的哪些backbone？

==目的==：因为客流检测是有实时性要求的，我们尽量希望减少模型的复杂度和模型的推理时间。一开始的话，我们尝试使用yolov3，但是使用yolov3的效果挺差的，它的测试的精度只有60多。然后就是很自然我们就会使用yolov4，为了使模型更加的轻量化，一开始我们使用yolov4 tinny，发现精度还是很低。然后就使用yolov4 cspdark53，测试的效果还不错，精度有85%左右。然后我就寻思，既然我们只有一类，backbone的特征提取网络应该不用很复杂。然后我就尝试删掉一些卷积层，看看能不能在保证精度的前提下，提高推理的速度。

yolov4中的backbone是有一系列的cspnet组成的。所谓的cps其实就是对于一个特征图进行两部分的处理，一个是输入到残差块中进行特征提取，另一个就是直接经过卷积，然后再将两个的处理结果进行合并，最后得出一个下采样的特征图，就是特征图的长和宽都减少一半，然后是通道数增加一倍。
		所以CPSdarknet53中，按照残差块中的卷积层的层数来分的话，一共有5个下采样的大残差块，大残差块中的卷积层数目分别是1，2，8，8，4。我觉得这个网络的残差块有点冗余，然后就是，将第三和第四个残差块中8个卷积层降为4个残差块。
		这样做的目的就是好为了，在保证精度的前提之下，减少模型的复杂度，通过减少模型的计算量达到一个加速的效果。
其实这个是可行的，因为我们在做这个实验之前，我们觉得这个检测任务得到的只有一类，所以特征提取网络可以不用太过复杂。但是又不能太过简单。

#### （3）kmeans++算法

==算法的背景==发我们为什么会用这个算法呢，因为对于anchor base的模型来说，anchor也就是先验框，这是一个超参数。这个超参数是需要我们人为确定的。像YOLOv4的话，它模型有推荐的anchor的尺寸，这个尺寸是根据大量的coco还有voc等数据统计得到的。我在用它提供的anchor的时候，我就觉得它的尺寸还是很合理，我特意比较了一下提供的尺寸和扶梯场景下的人头框的尺寸还是有点较大的差异。所以我才会想着要重新使用kmeans++算法对anchor进行聚类，得出比较尺寸比较合理的anchor。

==算法的步骤==首先说一下Kmeans算法，这个算法是用来进行聚类，得到不同尺度的anchor，这个anchor是用在YOLO模型上的。Kmeans算法的具体的过程是，
-》首先是要确定想要将数据聚类成几个类，比如我们这个项目我们想将这些先验的回归框分成9类，因为我们的yolo模型输出三个不同尺度的特征图，每一个特征图需要三种尺度的anchor，总共就是需要9类不同尺度的anchor。
-》下一步就是，kmans算法就是会随机选取k个点作为k类的中心，==kmeans++的话，它对于k个点的中心的选取有这样的要求，首先随机确定第一个点，对于剩下的点，尽量使它们的位置离已经确定的点尽量的远。这样就可以保证，在初始k个中心点的时候，各个类的距离比较远，这也是比较符合我们的先验的知识的。==
-》在确定完k个中心点之后，计算所有样本到这k个中心点的距离，我们挑选最小的距离作为该样本的类别。遍历完所有的样本之后，我们就可以得到，k个类以及每一个类中包含的样本，然后我们对每一类中的所有的样本求出它的中心点作为这个类的新的中心点。
-》进行迭代重复这个求解中心点的过程，直到到达一定的迭代次数，或者中心点收敛不变为止。然后我们就可以得到k个类的中心点以及属于每一个类的样本，这个k个点作为我们的anchor。

#### （4）关于CIoU和SIoU部分

介绍一下关于回归损失的发展历程。从L1到L2，然后从IoU到GIoU，然后到DIoU，然后到CIoU，最后到SIoU。这个IoU的发展历程都是为了解决某些问题而生的。比如说IoU的，如果检测框和GT没有相交的话，它们的loss就会恒为1，loss就是一个常数，常数的导数是0，然后梯度就是0，那么就没有办法继续更新权重参数了。

为了解决IoU的问题，然后提出了GIoU，它给预测框和GT加了一个outer的rectangle，就是外部的框，如果预测框和GT距离太远的话，这个外接的框也会越大，损失越大。解决了两个框如果不想交没有办法优化的问题。
		还有就是DIoU的目的就是最小化两个框的中心距离和外部框的对角线的长度，加快优化的速度。
		CIoU在DIoU的基础上增加了一个矩形框的长宽之比，就是把形状的损失也考虑进来了。
		==SIoU的话，它是在前面的基础上，考虑了角度的损失，这个角度就是检测框和GT的中心点的连线和水平线或者垂直线的角度，考虑这个角度损失的话，它可以是模型的优化收敛速度更快了。==

我的测试的效果的话，比较了一下，更改之后，训练速度大概快了10%左右，缩短了训练的时间。还有精度上有一点点提升。

### 2. 解决遮挡部分

#### （1） 数据方面

#### （2）NMS和soft-NMS以及自适应NMS的IoU，以及自适应置信度阈值

==NMS==：就是非极大值抑制。它是模型后处理的一部分内容，训练用不上这个，验证和测试的时候需要。它解决的问题是去除冗余的相交重复的检测框，就是一个目标，没有经过后处理的时候，它有可能会被一系列的检测框给框住。那么我们的目标就是尽量保留一个置信度最大的检测框，NMS就是解决这个问题的。
具体的步骤就是：
-》模型输出的检测框都会有一个置信度，表示这个boundingbox含有目标的概率是多少。首先我们会有一个置信度阈值，如果检测框的置信度小于这个阈值，那么它就会被过滤掉。
-》然后我们将剩余的检测框按照置信度的大小进行排序，降序。然后我们挑出置信度最大的，表明这个检测框是我们要保留的。然后用这个检测框和剩余的检测框求IoU，如果IoU越大的话，说明重叠度越高，如果高于我们设定的这个IoU阈值的话，NMS的话就会直接将它丢弃，但是soft-NMS的话，就会将这个它的置信度降低，不直接丢弃。
-》然后重复上述的过程，知道所有的待处理的检测框列表为空。
	==自适应NMS==：上面有一个问题，就是对于含有遮挡情况的两个检测框，即使模型可以把被遮挡的目标检测出来，soft-NMS一定程度可以减缓。但是还是可能会使被遮挡的目标被丢弃，所有，所以我就想了一个办法。当人流量多的时候，将IoU的阈值设置小一点，那么被遮挡的目标被丢弃的可能性就降低了。同时，也自适应检测框的置信度阈值，正常情况下是0.5，然后人多的时候，就是0.4 或者低一点。这样被遮挡的目标被丢弃的可能性会降低了。

#### （3）跟踪算法匹配解决这个问题

​		KM匹配算法的代价矩阵，这个矩阵的行对应的是检测框，列对应的是跟踪器的预测框，然后矩阵里面的值表示的是值就是检测框和预测框的IOU，就是它们的相似度。我们觉得这个相似度用IOU进行比较不够准确，就改成了使用DIoU。这样不仅更好地描述两者的重合度，还可以解决两个框不相交无法判断重合度的问题。



# ==二、 跟踪==

#### 1. 什么是卡尔曼滤波？为什么要用卡尔曼滤波？

​		==引入卡尔曼滤波器的原因==：这个是用来进行跟踪的。因为做人流检测的话，不仅仅是要将视频中的每一帧的人头给检测出来，还需要确定不同视频帧之间的人对应的是哪个。所以，就需要一个跟踪器。我们使用卡尔曼滤波器作为跟踪器。
​		==介绍卡尔曼滤波器==：
卡尔曼滤波器有重要的点：一个就是信息的融合，可以根据观测值（就是我们的检测模型的检测到的回归框的坐标）和卡尔曼滤波器中的运动方程，就是行人的行动方程，预测到的位置状态，然后融合这两者的信息，得到一个滤波之后的位置状态。这个位置状态可以更准确描述当前人的位置信息。

-》 还有就是，卡尔曼滤波跟踪器会记录一人从进入到ROI区域到走出ROI区域过程中的所有的位置信息，最后如果行人走进了ROI区域，我们会使用一个标志位对行人进行标记，当行人走出了ROI区域，我们就可以对总人数进行加1操作了。

#### 2. 什么是KM匹配算法

​		KM匹配算法的作用就是将卡尔曼滤波器中的运动方程预测到的预测框和检测框进行匹配起来。它会根据我们模型的检测框和跟踪器的预测框的相似度进行优先的匹配，直到所有的检测框都匹配完。那么用什么衡量这个相似度呢？一般使用的就是IOU，可以看两个框的重合的程度。但是我觉得但是IOU不够准确，所以就用了DIoU，这个可以解决两个框不重叠的情况下依然可以表征它们的重合度。

# ==三、 扶手带==

#### 1. 高斯混合模型

-》 其它的方法：平均背景差分法；帧间差分法；效果不好，容易收到光照变化的影响。

# ==四、模型部署==


#### 1. 步骤

首先是将我们训练好的模型权重配置文件，转化成onnx模型。
然后调用trt的库的接口，构建一个engine，就是tensorrt的engine
然后使用这个engine对象解析onnx模型，那么就可以得到后缀名为.engine的疼搜让人头的文件了。
然后我们可以给定输入，经过这个engine对象就可以得到输出。这个推理过程是经过了优化和加速的。

#### 2. INT8量化
-》 就是模型的权重和特征图都是用8位内存来表示，可以减少计算量。达到加速的效果。
-》 在engine中指定int8模式就可以了。具体的量化过程是没有开源的。不过我们需要给定矫正图像，让tensorrt模型跑一遍，找到最优的量化策略。

# ==五、比赛==
#### 0. 比赛介绍
​	这个是阿里天池的一个比赛。比赛的任务就是，给定一个固定的分类模型，还有一万张固定的图像数据。要去我们不能更改模型，只能更改数据，最多可以生成或者制造6万张图像数据，其实就是一个数据的增强，然后用我们生成制造的数据来训练这个固定的模型，要尽量我们训练出来的模型具有鲁棒性。那么怎样评判我们模型的好坏呢，比赛方会要求我们提交我们生成的数据以及训练好的模型，然后用他们自己的数据来测试，然后将测试结果作为我们的分数。
​	我们使用的方法包括传统的数据生成的方法，比如加噪声，形状变换，颜色抖动，亮度变化等等。同时我们也使用了一些高级的策略，想cutout，cutmix，mixup等等。上面的这些方法都是基于原有的数据集进行更改的，我们还采用了DCGAN和风格迁移进行生成新的数据。最后的话，我们使用每一种数据增强的方法，调整数据生成的比例，取得比较好的效果。

#### 1. 传统的方法
​	裁剪、形变、加噪、颜色抖动、仿射变换。
#### 2. 一些高级的策略
[数据增强 - Cutout、Random Erasing、Mixup、Cutmix](https://blog.csdn.net/irving512/article/details/113846570)
#### 3. 比赛的难点

1. 从图片本身的角度考虑，像素只有32x32，因为这个是cifar数据集。图像本身就是很模糊的，有些图片肉眼上就比较难区分出来是属于哪一个类别，存在模棱两可的情况。对于这种情况，我么采取的方法是首先进行数据的清洗，进行反复的交叉验证实验，记录哪些错分的样本，记录它们的loss，如果是严重错分的话，就去掉。

2. 给定的数据集一共有10类，其中我们发现有些类之间很像。比如卡车和小汽车，飞机和鸟。我们是通过测试和训练结果来看出来的。


2. 我们不知道具体的测试集的数据是怎样的。这个比赛的任务是要求我们训练一个鲁棒的机器学习模型，鲁棒不鲁棒不是我们自己说的，是由比赛举办方使用它们的测试集来判断的。如果我们处理的数据集的数据分布和测试集的数据分布比价接近的话，效果会更好。所以对于这个问题，我们采取了各种方法，每一种方法都分别生成一些数据，然后汇总起来，尽量使数据的分布更具有广泛性和适用性。

#### 4. DCGAN

* DCGAN的原理
  GAN就是生成对抗性网络的意思。这是一个网络，DC表示的是由直接的卷积层组成的网络。这个模型的组成的话，有两部分，一个是生成器，另一个是判别器。然后说一下它们的工作原理，生成器的输入就是一个随机数，输出一张我们希望得到的图像，这个图像我们希望它和我们的目标很像。然后判别器本质上就是一个分类器，我们把原来真实的数据的标签标为1，我们通过生成器生成的样本数据的标签标为0。假设我们已经提前训练了分类器，把我们的真实样本和生成的样本打好标签之后，给到分类器去进行分类，如果分类器的识别率很高，就是说分类器很容易识别出生成器生成的是假的样本，我们就人为生成器的性能不足，并且以分类器的结果作为生成器的loss，继续训练生成器，直到生成器生成的图像数据被判别器无法识别为是真样本还是假样本的地步为止。
* ==引入这个的DCGAN的原因==
  因为GAN是典型的数据增强的方法。我们可以通过它来生成一些新的数据。这些数据具有原来的object有具有的特征，但是又和原来的图像不一样，这种不一样是和那种对原图通过形变，颜色变换，加噪声或者滤波之后的图像不一样。传统的方法都是基于原图进行修改，得到的其实是和原图差不多特征的数据。而GAN生成的是完全新的数据，并且这个数据和要表征的object很逼真，丰富了特征的多样性。这是一种更加高级的数据增强的方法。
  最基本的GAN网络，它的网络内部是使用全连接层搭建的。DCGAN使用的是卷积层搭建的。实验证明DCGAN的效果比GAN的效果要好。为什么？
  -》GAN可以用来拟合原始的数据分布，什么叫做拟合数据分布，就是给你一个训练数据，你能通过GAN这个工具，产生和这个数据分布相似的一些数据。
* ==DCGAN和GAN的区别==
	[GANs系列：DCGAN原理简介与基础GAN的区别对比](https://blog.csdn.net/m0_62128864/article/details/123906876)
#### 5. 快速风格迁移部分

​	==模型的介绍==风格迁移的模型也是有两个部分组成；一个模型是用来生成我们所需要的图像，然后这个模型输出这个图像；然后另一个模型的话，对生成模型输出的图像和原来的图像以及风格图像进行比较，模型将它们的差异作为一个损失，那么我们就可以优化这个损失，最后比较理想的话，生成的图像既保留了原来图像的形状信息又有风格图像的风格信息。
​	==引入这个的原因==： 对一张图像改变了风格之后，原来图像的风格就改变了，所谓的风格改变，其实就是原来图像的一些纹理特征或者一些很细节的特征被改变了，然后留下了形状特征。这样的话，如果后续分类器对这个图像进行学习的话，会学习到更加多的形状信息，更加关注它的形状。其实要分辨一样物体，有时候单是关注形状就可以进行辨认了，比如我们看到汽车的外形，看到轮船的外形就知道它是什么了。

#### 6. 自己负责的部分

1. 服务器的环境配置，shell脚本的编写实现程序自动依次读取候选训练数据集，实现训练后数据和模型的自动整理和打包；

2. 基础模型代码的重构，在基础代码模块下，加入模型验证模块、数据增强模块、数据清洗模块、基于argparse的命令行模块等；

3. 数据增强方法的参数的调试，增强数据的比例的选取，代码的debug等。
==具体==
* 验证部分；我们使用了五折交叉验证，就是将一个数据集分成5分，挑选其中一份作为验证，然后其它的四分用来作为训练。
* 交叉验证，数据的结果的可视化，写出来每一个分类的结果，哪些错分了哪些。
* 上面的交叉验证完了之后，就进行数据的清晰工作，去掉那些loss很大的，无论怎样分都是错误的，我认为这些数据集都我们的模型是没有作用的。数据清洗部分。
* 重写了原来的，整合了训练和测试，加入了argparse部分，目的是为了使用命令进行调用，比如我们在命令行可以指定工作目录，可以指定使用什么样的数据进行训练等等。。
* 加入了中断训练保护部分。有时候会因为其它的原因中途断掉。中途可以重新加载。
* 写了自动训练的脚本，我们把需要准备训练好的数据放在一个文件夹里面，写好一个shell脚本，训练完一个，实现自动打包和压缩功能，这个可以直接进行提高了。并且
     记录了训练的log。这里要解释一下，为什么要这样做。前期：只能是白天进行手动训练，晚上如果一个模型训练完之后，没有办法人工控制。感觉没有很好利用好这个资源，所以就重新就
* 重新加入了命令行参数的形式，并且写好了相应的脚本，部署好，大大提高了我们的训练效率。

# ==六、工作==
#### 1. 介绍一下以前的工作。公司。职位。
本科从华南理工大学毕业之后，去了深圳的一家公司上班，这个公司叫做洲明科技股份有限公司，是一家做LED显示屏的制造业公司，在LED显示屏这块，排名是全球前三的企业。我在这个企业呆了一年多，差不多两年。后面就离职了，然后就考上研究生回来读研了。
我当时的职位是：在它们公司的研发中心，担任电子工程师。具体的工作内容的话，比较的泛，但凡是和电子、电气相关的话，都会沾边。比如说，像画显示模组的原理图、像电子物料的选型、像电气配置等等。还有就是要对接产品，对接生产，指导生产，处理生产异常等等，还有处理客诉。处理订单等等。还有进行产品的测试。
#### 2. 离职的原因。
总体来说，就是自己的兴趣以及一些客观的原因吧。
（1）自己的岗位是电子工程师，做的一些工作比较的烦杂。
（2）对焊锡中的松香的味道有点过敏。自己要经常性的焊板子，进行测试。闻到松香的味道鼻子不是很舒服。
（2）自己对于软件、coding这个块可能会更加的感兴趣一点。所以考研回来就学着一块的。
（3）还有就是本科的时候，跟老师做srp的时候，发现自己对软件比价感兴趣。老师当时还叫我读研。因为我的成绩比较的好。
# ==七、HR面试==
#### 1. 性格特点

#### 2. 优点和缺点

#### 3. 自己的职业发展规划