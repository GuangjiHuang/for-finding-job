# ==0. 自我介绍==

（1）面试官您好，首先就是非常感觉您能够抽出宝贵的时间来面试我。我叫黄光积。本科和硕士都是就读于华南理工大学的自动化学院。现在是刚上研三，明年毕业。我的研究方向是是关于人工智能这一块的，研究的课题是智能扶梯监控。

（2）我的简历上写了一个项目和比赛。然后呢这个项目也是我课题做的方向，这是一个广州市科技局的项目，是我们实验室和日立电梯那边合作一起合作的。它的任务是要开发一个手扶电梯智能监控系统，实现扶梯场景下的客流统计以及扶手带上的异物探出的检测。我负责的是这个智能系统的算法实现。在客流统计这个任务上，我们做到的算法的准确率达到96%。在扶手带异物检测这个任务上，我们做到的异物检测准确率达到95%。然后使用Tensort框架将模型部署到英伟达的Jetson Xavier嵌入式平台上，达到27FPS的实时检测效果。

（3）研究生期间我还和实验室的同学组队参加了阿里天池的一个比赛。这个比赛是以数据为中心的鲁棒机器学习。它的任务就是给定一定的图片的数据，让我们训练出一个效果比较好的鲁棒的模型。然后就是我们取得的成绩是：初赛成绩是在3000多支队伍中排名40多名，复赛成绩是在50支队伍中排名37名。我的自我介绍完毕，请多多指教，谢谢！


# ==一. 检测==

### 1. 模型修改部分

#### （1）介绍一下copy paste

​	==背景和目的==：使用这个方法是为了解决数据的跨域训练和测试的问题，深度学习一般会出现这样的一个情况，就是使用数据集训练好了一个模型，然后在应用这个模型进行推理测试的时候，在某些场景下，效果可能会很好，但是在另外一下场景下的效果不好。并且我们这个训练集的人头数据并不是都来源于扶梯的场景，而是大多的数据都是来源于其它的场景，因为这是一个公共的数据集，比如说是教室，会议室等场景。因为需要保密的问题，实际上的扶梯的数据集是不能泄漏的，所以找不到真正扶梯应用场景下大量数据集。然后就是，我们向企业那边拿了一些数据集，数据集也是非常的有限，这个数据集我们都用作了测试集。
​	引入copy paste就是解决这样的一个问题，就是训练集上的数据的场景和实际应用的场景的不同的问题。其实，现实中，这种问题应该会比较的常见。效果的话，应用了copy paste，大概可以可高3个百分点。

copy paste翻译过来就是复制粘贴，就是从别的场景下标注的数据复制过来，然后粘贴到我们实际使用的应用场景，比如现在我们项目的这个扶梯下的场景。
这是一个数据增强的方法，在模型训练之前进行处理的。

copy paste还可以解决一个正样本和负样本极度不均衡的问题，比如说一般的图像，整张图可能就是几个目标人头，也就是说正样本的数量是非常的少的。但是我们在进行copy paste之后，一个图像的目标数会比较的多，roi区域的目标数相对会比较的稠密。增加了正样本的数量。



#### （2）改变了模型的哪些backbone？

==目的==：因为客流检测是有实时性要求的，我们尽量希望减少模型的复杂度和模型的推理时间。一开始的话，我们尝试使用yolov3，但是使用yolov3的效果挺差的，它的测试的精度只有60多。然后就是很自然我们就会使用yolov4，为了使模型更加的轻量化，一开始我们使用yolov4 tinny，发现精度还是很低。然后就使用yolov4 cspdark53，测试的效果还不错，精度有85%左右。然后我就寻思，既然我们只有一类，backbone的特征提取网络应该不用很复杂。然后我就尝试删掉一些卷积层，看看能不能在保证精度的前提下，提高推理的速度。

yolov4中的backbone是有一系列的cspnet组成的。所谓的cps其实就是对于一个特征图进行两部分的处理，一个是输入到残差块中进行特征提取，另一个就是直接经过卷积，然后再将两个的处理结果进行合并，最后得出一个下采样的特征图，就是特征图的长和宽都减少一半，然后是通道数增加一倍。
		所以CPSdarknet53中，按照残差块中的卷积层的层数来分的话，一共有5个下采样的大残差块，大残差块中的卷积层数目分别是1，2，8，8，4。我觉得这个网络的残差块有点冗余，然后就是，将第三和第四个残差块中8个卷积层降为4个残差块。
		这样做的目的就是好为了，在保证精度的前提之下，减少模型的复杂度，通过减少模型的计算量达到一个加速的效果。
其实这个是可行的，因为我们在做这个实验之前，我们觉得这个检测任务得到的只有一类，所以特征提取网络可以不用太过复杂。但是又不能太过简单。

#### （3）kmeans++算法

==算法的背景==发我们为什么会用这个算法呢，因为对于anchor base的模型来说，anchor也就是先验框，这是一个超参数。这个超参数是需要我们人为确定的。想YOLOv4的话，它模型有推荐的anchor的尺寸，这个尺寸是根据大量的coco还有voc等数据统计得到的。我在用它提供的anchor的时候，我就觉得它的尺寸还是很合理，我特意比较了一下提供的尺寸和扶梯场景下的人头框的尺寸还是有点较大的差异。所以我才会想着要重新使用kmeans++算法对anchor进行聚类，得出比较尺寸比较合理的anchor。

==算法的步骤==首先说一下Kmeans算法，这个算法是用来进行聚类，得到不同尺度的anchor，这个anchor是用在YOLO模型上的。Kmeans算法的具体的过程是，
-》首先是要确定想要将数据聚类成几个类，比如我们这个项目我们想将这些先验的回归框分成9类，因为我们的yolo模型输出三个不同尺度的特征图，每一个特征图需要三种尺度的anchor，总共就是需要9类不同尺度的anchor。
-》下一步就是，kmans算法就是会随机选取k个点作为k类的中心，==kmeans++的话，它对于k个点的中心的选取有这样的要求，首先随机确定第一个点，对于剩下的点，尽量使它们的位置离已经确定的点尽量的远。这样就可以保证，在初始k个中心点的时候，各个类的距离比较远，这也是比较符合我们的先验的知识的。==
-》在确定完k个中心点之后，计算所有样本到这k个中心点的距离，我们挑选最小的距离作为该样本的类别。遍历完所有的样本之后，我们就可以得到，k个类以及每一个类中包含的样本，然后我们对每一类中的所有的样本求出它的中心点作为这个类的新的中心点。
-》进行迭代重复这个求解中心点的过程，直到到达一定的迭代次数，或者中心点收敛不变为止。然后我们就可以得到k个类的中心点以及属于每一个类的样本，这个k个点作为我们的anchor。

#### （4）关于CIoU和SIoU部分

介绍一下关于回归损失的发展历程。从L1到L2，然后从IoU到GIoU，然后到DIoU，然后到CIoU，最后到SIoU。这个IoU的发展历程都是为了解决某些问题而生的。比如说IoU的，如果检测框和GT没有相交的话，它们的loss就会恒为1，loss就是一个常数，常数的导数是0，然后梯度就是0，那么就没有办法继续更新权重参数了。

为了解决IoU的问题，然后提出了GIoU，它给预测框和GT加了一个outer的rectangle，就是外部的框，如果预测框和GT距离太远的话，这个外接的框也会越大，损失越大。解决了两个框如果不想交没有办法优化的问题。
		还有就是DIoU的目的就是最小化两个框的中心距离和外部框的对角线的长度，加快优化的速度。
		CIoU在DIoU的基础上增加了一个矩形框的长宽之比，就是把形状的损失也考虑进来了。
		==SIoU的话，它是在前面的基础上，考虑了角度的损失，这个角度就是检测框和GT的中心点的连线和水平线或者垂直线的角度，考虑这个角度损失的话，它可以是模型的优化收敛速度更快了。==

我的测试的效果的话，比较了一下，更改之后，训练速度大概快了10%左右，缩短了训练的时间。还有精度上有一点点提升。

### 2. 解决遮挡部分

#### （1） 数据方面

#### （2）NMS和soft-NMS以及自适应NMS的IoU，以及自适应置信度阈值

==NMS==：就是非极大值抑制。它是模型后处理的一部分内容，训练用不上这个，验证和测试的时候需要。它解决的问题是去除冗余的相交重复的检测框，就是一个目标，没有经过后处理的时候，它有可能会被一系列的检测框给框住。那么我们的目标就是尽量保留一个置信度最大的检测框，NMS就是解决这个问题的。
具体的步骤就是：
-》模型输出的检测框都会有一个置信度，表示这个boundingbox含有目标的概率是多少。首先我们会有一个置信度阈值，如果检测框的置信度小于这个阈值，那么它就会被过滤掉。
-》然后我们将剩余的检测框按照置信度的大小进行排序，降序。然后我们挑出置信度最大的，表明这个检测框是我们要保留的。然后用这个检测框和剩余的检测框求IoU，如果IoU越大的话，说明重叠度越高，如果高于我们设定的这个IoU阈值的话，NMS的话就会直接将它丢弃，但是soft-NMS的话，就会将这个它的置信度降低，不直接丢弃。
-》然后重复上述的过程，知道所有的待处理的检测框列表为空。
	==自适应NMS==：上面有一个问题，就是对于含有遮挡情况的两个检测框，即使模型可以把被遮挡的目标检测出来，soft-NMS一定程度可以减缓。但是还是可能会使被遮挡的目标被丢弃，所有，所以我就想了一个办法。当人流量多的时候，将IoU的阈值设置小一点，那么被遮挡的目标被丢弃的可能性就降低了。同时，也自适应检测框的置信度阈值，正常情况下是0.5，然后人多的时候，就是0.4 或者低一点。这样被遮挡的目标被丢弃的可能性会降低了。

#### （3）跟踪算法匹配解决这个问题



# ==二、 跟踪==

#### （1）什么是卡尔曼滤波？为什么要用卡尔曼滤波？

#### （2）什么是KM匹配算法

# ==三、 扶手带==

#### （1）高斯混合模型

#### （2）自适应面积阈值

# ==四、模型部署==

# ==五、比赛==

#### 传统的方法

#### 一些高级的策略

#### DCGAN

#### 快速风格迁移部分

#### 自己负责的部分

